{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n",
      "Accuracy for testing dataset: 75.196850\n",
      "\n",
      "Test result for H.W dataset is [1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sample code for bayesian approach\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "filename = 'sampleDataset.csv'\n",
    "lines = csv.reader(open(filename, \"r\")) # read the csv file ('open' - see https://docs.python.org/3/library/functions.html)\n",
    "dataset = list(lines)\n",
    "\n",
    "for i in range(len(dataset)): # this two lines are equivalent to the following \"for\" statement\n",
    "    dataset[i] = [float(x) for x in dataset[i]] # convert to float type\n",
    "#for i in range(len(dataset)): # convert the data type in dataset to float type\n",
    "#    for j in range(len(dataset[i])):\n",
    "#        dataset[i][j] = float(dataset[i][j])\n",
    "\n",
    "# prepare training dataset and testing dataset\n",
    "splitRatio = 0.67 # 2/3 for training and 1/3 for testing\n",
    "trainSize = int(len(dataset) * splitRatio)\n",
    "trainSet = []\n",
    "copy = list(dataset)\n",
    "while len(trainSet) < trainSize:\n",
    "    index = random.randint(0, len(copy)-1) # randomly pick one number between 0 and dataset size\n",
    "    trainSet.append(copy.pop(index))\n",
    "    # pop: Remove the item at the given position in the list\n",
    "    # append: Add an item to the end of the list\n",
    "#    print(index) # un-comment to see the indexes selected\n",
    "testSet = copy\n",
    "print('Split %d rows into train=%d and test=%d rows' % (len(dataset), len(trainSet), len(testSet)))\n",
    "    \n",
    "# prepare model\n",
    "#    separated by class\n",
    "separated = {} # create an empty dictionary\n",
    "for i in range(len(trainSet)):\n",
    "    vector = trainSet[i] # Note that the last element in dataset is the 'label'\n",
    "    # create a key and add a blank array to it\n",
    "    if (vector[-1] not in separated): # vector[-1] refers to the last element (count from the right)\n",
    "        separated[vector[-1]] = []\n",
    "    separated[vector[-1]].append(vector) # store separately datasets corresponding to their accessing keys (e.g., labels, 0.0 and 1.0) -- e.g., {1: [[6.0, 119.0, 50.0, 22.0, 176.0, 27.1, 1.318, 33.0, 1.0], [6.0, 119.0, 50.0, 22.0, 176.0, 27.1, 1.318, 33.0, 1.0]], 2: []} \n",
    "\n",
    "# mean and std summarized by class\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1) # pow: Return x to the power y\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "summaries = {}\n",
    "for classValue, instances in separated.items(): # learn the distribution parameters with the TrainSet\n",
    "    summaries[classValue] = [(mean(attribute), stdev(attribute)) for attribute in zip(*instances)] # calculate separatedly the mean and std for each attribute/feature (e.g., labels, 0.0 and 1.0)\n",
    "    \"\"\" zip() - built-in function\n",
    "    >>> x = [1, 2, 3]\n",
    "    >>> y = [4, 5, 6]\n",
    "    >>> zipped = list(zip(x, y))\n",
    "    >>> zipped\n",
    "    [(1, 4), (2, 5), (3, 6)]\n",
    "    >>> x2, y2 = zip(*zipped)\n",
    "    >>> x == list(x2) and y == list(y2)\n",
    "    True\n",
    "    \"\"\"\n",
    "    del summaries[classValue][-1] # delete the label attribute\n",
    "# print(summaries) # to see what is stored\n",
    "\n",
    "# calculate the probability that each label occurs (e.g., P(class) such as P(0) & P(1))\n",
    "probability_label_0 = len(separated[0]) / len(trainSet)\n",
    "probability_label_1 = len(separated[1]) / len(trainSet)\n",
    "probability_label= [probability_label_0, probability_label_1]\n",
    "\n",
    "# test model\n",
    "def calculateProbability(x, mean, stdev): # to calculate P(x | class), the probability for x (the dataset which we are predicting the label for)\n",
    "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    " \n",
    "# to predict the label with datasets (testSet)\n",
    "# testSet = trainSet # un-comment to switch the datasets when calculting the accuracy for trainSet\n",
    "predictions = []\n",
    "for h in range(len(testSet)):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1 * probability_label[int(classValue)] # initialization\n",
    "       \n",
    "        for i in range(len(classSummaries)): # len(classSummaries) = the number of features\n",
    "            mean, stdev = classSummaries[i]            \n",
    "            x = testSet[h][i] # testSet[0] = the first datapoint & testSet[0][0] = value of the firt feature of the first datapoint\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev) # to calculate P(class | x) by P(class)* P(x1 | class) * P(x2 | class) ...\n",
    "    # predict the label: Decision Rule\n",
    "    if probabilities[0] > probabilities[1]:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)  \n",
    " \n",
    "# calculate the accuracy\n",
    "correct = 0\n",
    "for i in range(len(testSet)):\n",
    "    if testSet[i][-1] == predictions[i]:\n",
    "        correct += 1\n",
    "accuracy = (correct/float(len(testSet))) * 100.0\n",
    "print('Accuracy for testing dataset: %f' % accuracy)\n",
    "\n",
    "\n",
    "\"\"\" Question: What are the labels you predict using the trained Bayesian model for the new datasets below?\n",
    "[10, 139, 80, 0, 0, 27.1, 1.441, 57]\n",
    "[10, 115, 70, 10, 100, 40.1, 0.421, 30]\n",
    "[5, 196, 65, 30, 55, 37.1, 0.247, 41]\n",
    "[7, 97, 75, 31, 213, 24.5, 0.845, 37]\n",
    "[6, 109, 76, 0, 52, 43.2, 2.041, 33]\n",
    "\"\"\"\n",
    "#########################################################################\n",
    "\n",
    "New_prediction=[\n",
    "    [10, 139, 80, 0, 0, 27.1, 1.441, 57],\n",
    "    [10, 115, 70, 10, 100, 40.1, 0.421, 30],\n",
    "    [5, 196, 65, 30, 55, 37.1, 0.247, 41],\n",
    "    [7, 97, 75, 31, 213, 24.5, 0.845, 37],\n",
    "    [6, 109, 76, 0, 52, 43.2, 2.041, 33]\n",
    "]\n",
    "predictions2 = []\n",
    "for h in range(len(New_prediction)):\n",
    "    probabilities2 = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities2[classValue] = 1 * probability_label[int(classValue)]\n",
    "       \n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]            \n",
    "            x = New_prediction[h][i]\n",
    "            probabilities2[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    if probabilities2[0] > probabilities2[1]:\n",
    "        predictions2.append(0)\n",
    "    else:\n",
    "        predictions2.append(1)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Test result for H.W dataset is\", predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
